---
layout: '../layouts/ContentLayout.astro'
title: "Glossary of Terms"
description: "Comprehensive glossary of probability theory, statistics, and computational terms used throughout the guide"
---

import Callout from '../components/ui/Callout.astro';
import Pager from '../components/ui/Pager.astro';
import OnThisPage from '../components/ui/OnThisPage.astro';

<OnThisPage slot="sidebar" headings={[
  { depth: 2, slug: 'a', text: 'A' },
  { depth: 2, slug: 'b', text: 'B' },
  { depth: 2, slug: 'c', text: 'C' },
  { depth: 2, slug: 'd', text: 'D' },
  { depth: 2, slug: 'e', text: 'E' },
  { depth: 2, slug: 'f', text: 'F' },
  { depth: 2, slug: 'g', text: 'G' },
  { depth: 2, slug: 'h', text: 'H' },
  { depth: 2, slug: 'i', text: 'I' },
  { depth: 2, slug: 'mathematical-notation', text: 'Mathematical Notation Reference' },
  { depth: 2, slug: 'common-distributions', text: 'Common Distributions Quick Reference' }
]} />

# Glossary of Terms

This comprehensive glossary defines key terms used throughout the guide, organized alphabetically for easy reference.

<Callout variant="note">
**How to Use This Glossary**

Terms are defined with their mathematical notation (where applicable) and practical interpretation. Cross-references to related terms are indicated in *italics*.
</Callout>

## A

**Axioms of Probability**: The three fundamental rules established by Kolmogorov that any valid probability measure must satisfy: (1) Non-negativity: P(A) ≥ 0, (2) Normalization: P(Ω) = 1, (3) Countable additivity: P(A₁ ∪ A₂ ∪ ...) = P(A₁) + P(A₂) + ... for mutually exclusive events.

## B

**Bayes' Theorem**: A fundamental result in probability theory that describes how to update probabilities based on new evidence: P(A|B) = P(B|A) × P(A) / P(B). Forms the foundation of *Bayesian inference*.

**Bayesian Inference**: A statistical approach that treats parameters as random variables with probability distributions, allowing for the incorporation of prior knowledge and the quantification of uncertainty in parameter estimates.

**Bernoulli Distribution**: A discrete probability distribution for a random variable that takes value 1 with probability p and value 0 with probability 1-p. Named after Jacob Bernoulli.

**Beta Distribution**: A continuous probability distribution defined on the interval [0,1], commonly used as a prior distribution for probabilities in *Bayesian analysis*. Parameterized by shape parameters α and β.

**Binomial Distribution**: A discrete probability distribution that models the number of successes in n independent *Bernoulli trials*, each with success probability p. Denoted as Binomial(n,p).

**Brownian Motion**: A continuous-time *stochastic process* that models random motion, fundamental in physics and finance. Also known as a Wiener process.

## C

**Central Limit Theorem (CLT)**: A fundamental theorem stating that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population distribution (under certain conditions).

**Conditional Probability**: The probability of an event A occurring given that another event B has occurred, denoted P(A|B). Calculated as P(A|B) = P(A ∩ B) / P(B) when P(B) > 0.

**Confidence Interval**: A range of values that is likely to contain the true value of a population parameter with a specified level of confidence (e.g., 95%). Not to be confused with *credible intervals* in Bayesian statistics.

**Correlation**: A measure of the linear relationship between two variables, ranging from -1 to 1. Does not imply causation.

**Credible Interval**: In *Bayesian statistics*, an interval that contains the parameter of interest with a specified probability based on the posterior distribution.

**Cumulative Distribution Function (CDF)**: A function F(x) = P(X ≤ x) that gives the probability that a random variable X takes a value less than or equal to x.

## D

**Degrees of Freedom**: The number of independent pieces of information available to estimate a parameter or calculate a statistic. Important in *hypothesis testing* and confidence interval construction.

**Discrete Distribution**: A probability distribution for a random variable that can take on only countable values (finite or countably infinite).

## E

**Event**: A subset of the *sample space* representing a collection of possible outcomes of a random experiment.

**Expected Value (Mean)**: The average value of a random variable, calculated as E[X] = Σ x·P(X=x) for discrete variables or E[X] = ∫ x·f(x)dx for continuous variables.

**Exponential Distribution**: A continuous probability distribution often used to model waiting times between events in a Poisson process. Has the memoryless property.

## F

**Frequentist Statistics**: A statistical approach that interprets probability as the long-run frequency of events and treats parameters as fixed but unknown constants.

## G

**Gamma Distribution**: A continuous probability distribution that generalizes the *exponential distribution*. Often used in *Bayesian analysis* as a conjugate prior for precision parameters.

**Gaussian Process**: A collection of random variables, any finite number of which have a joint Gaussian distribution. Used in machine learning for regression and classification with uncertainty quantification.

## H

**Hypothesis Testing**: A statistical method for making decisions about population parameters based on sample data. Involves formulating null and alternative hypotheses and calculating test statistics.

## I

**Independence**: Two events A and B are independent if P(A ∩ B) = P(A) × P(B), meaning the occurrence of one does not affect the probability of the other.

**Inference**: The process of drawing conclusions about a population based on sample data. Can be *frequentist* or *Bayesian*.

## J

**Joint Distribution**: The probability distribution of two or more random variables considered together, describing their simultaneous behavior.

## K

**Kolmogorov Axioms**: See *Axioms of Probability*.

## L

**Law of Large Numbers**: A theorem stating that as the number of trials increases, the sample average converges to the expected value (population mean).

**Likelihood**: In statistics, the likelihood function L(θ|data) represents the probability of observing the given data as a function of the parameter θ.

**Log-likelihood**: The natural logarithm of the *likelihood* function, often used in optimization because it converts products to sums and is numerically more stable.

## M

**Marginal Distribution**: The probability distribution of a subset of random variables from a joint distribution, obtained by integrating or summing over the other variables.

**Markov Chain**: A *stochastic process* where the future state depends only on the current state, not on the sequence of events that led to it (Markov property).

**Markov Chain Monte Carlo (MCMC)**: A class of algorithms for sampling from probability distributions by constructing a *Markov chain* that has the desired distribution as its equilibrium distribution.

**Maximum Likelihood Estimation (MLE)**: A method for estimating parameters by finding the values that maximize the *likelihood* function.

**Monte Carlo Method**: A computational technique that uses random sampling to solve mathematical problems, particularly useful for integration and optimization.

## N

**Normal Distribution**: A continuous probability distribution characterized by its bell-shaped curve, defined by mean μ and standard deviation σ. Also called Gaussian distribution.

**Null Hypothesis**: In *hypothesis testing*, the default assumption that there is no effect or no difference. Typically denoted H₀.

## O

**Outlier**: An observation that lies an abnormal distance from other values in a dataset, potentially indicating measurement error or a different underlying process.

## P

**P-value**: In *hypothesis testing*, the probability of obtaining test results at least as extreme as the observed results, assuming the *null hypothesis* is true.

**Posterior Distribution**: In *Bayesian inference*, the probability distribution of parameters after observing data, combining the *prior distribution* with the *likelihood*.

**Prior Distribution**: In *Bayesian inference*, the probability distribution representing initial beliefs about parameters before observing data.

**Probability Density Function (PDF)**: For continuous random variables, a function f(x) such that the probability of X falling in an interval [a,b] is ∫ₐᵇ f(x)dx.

**Probability Mass Function (PMF)**: For discrete random variables, a function p(x) = P(X = x) that gives the probability of each possible value.

**Probability Space**: The mathematical framework (Ω, F, P) consisting of a *sample space* Ω, an *event space* F, and a *probability measure* P.

## Q

**Quantile**: The value below which a certain percentage of observations fall. For example, the 95th quantile is the value below which 95% of observations lie.

**Quasi-Monte Carlo**: A variant of *Monte Carlo methods* that uses low-discrepancy sequences instead of random numbers to achieve better convergence rates.

## R

**Random Variable**: A function that assigns numerical values to the outcomes of a random experiment. Can be discrete or continuous.

**Random Walk**: A mathematical formalization of a path consisting of a succession of random steps, fundamental in modeling various phenomena.

## S

**Sample Space**: The set of all possible outcomes of a random experiment, denoted Ω (omega).

**Sampling Distribution**: The probability distribution of a statistic (like the sample mean) over all possible samples of a given size from a population.

**Standard Deviation**: The square root of the *variance*, measuring the spread of a distribution in the same units as the original data.

**Statistical Significance**: A determination that an observed effect is unlikely to have occurred by chance alone, typically when the *p-value* is less than a chosen threshold (e.g., 0.05).

**Stochastic Process**: A collection of random variables indexed by time or space, used to model systems that evolve randomly over time.

## T

**Type I Error**: In *hypothesis testing*, the error of rejecting a true *null hypothesis* (false positive). The probability of Type I error is denoted α.

**Type II Error**: In *hypothesis testing*, the error of failing to reject a false *null hypothesis* (false negative). The probability of Type II error is denoted β.

## U

**Uniform Distribution**: A probability distribution where all outcomes in a given range are equally likely. Can be discrete or continuous.

**Uncertainty Quantification**: The process of characterizing and communicating uncertainty in mathematical models and their predictions.

## V

**Variance**: A measure of the spread of a probability distribution, calculated as the expected value of the squared deviation from the mean: Var(X) = E[(X - E[X])²].

**Variational Inference**: An approximate *Bayesian inference* method that transforms the inference problem into an optimization problem by finding the best approximation to the *posterior distribution* within a specified family.

## W

**Weibull Distribution**: A continuous probability distribution often used in reliability analysis and survival analysis to model time-to-failure data.

## Mathematical Notation Reference

| Symbol | Meaning |
|--------|---------|
| Ω | Sample space |
| F | Event space (σ-algebra) |
| P | Probability measure |
| A, B, C | Events |
| Aᶜ | Complement of event A |
| A ∪ B | Union of events A and B |
| A ∩ B | Intersection of events A and B |
| P(A\|B) | Conditional probability of A given B |
| X, Y, Z | Random variables |
| E[X] | Expected value of X |
| Var(X) | Variance of X |
| f(x) | Probability density function |
| F(x) | Cumulative distribution function |
| p(x) | Probability mass function |
| θ | Parameter (theta) |
| μ | Mean (mu) |
| σ | Standard deviation (sigma) |
| σ² | Variance |
| α | Significance level (alpha) |
| β | Type II error probability (beta) |
| λ | Rate parameter (lambda) |

## Common Distributions Quick Reference

| Distribution | Parameters | Mean | Variance | Use Cases |
|-------------|------------|------|----------|-----------|
| Bernoulli | p | p | p(1-p) | Single trial success/failure |
| Binomial | n, p | np | np(1-p) | Number of successes in n trials |
| Poisson | λ | λ | λ | Count of rare events |
| Normal | μ, σ² | μ | σ² | Continuous measurements |
| Exponential | λ | 1/λ | 1/λ² | Time between events |
| Uniform | a, b | (a+b)/2 | (b-a)²/12 | Equal likelihood over interval |
| Beta | α, β | α/(α+β) | αβ/[(α+β)²(α+β+1)] | Probabilities, proportions |
| Gamma | α, β | α/β | α/β² | Positive continuous values |

<Callout variant="tip">
**Using This Glossary**

- Terms are cross-referenced with related concepts in *italics*
- Mathematical notation follows standard conventions
- Practical interpretations accompany formal definitions
- Use Ctrl+F (Cmd+F on Mac) to search for specific terms
</Callout>

<Pager 
  prev={{ title: "References", href: "/references" }}
  next={{ title: "Labs", href: "/labs" }}
/>
